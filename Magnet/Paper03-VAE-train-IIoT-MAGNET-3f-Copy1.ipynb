{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ee0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juba\\.conda\\envs\\py3.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "lb_make=LabelEncoder()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import mse\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f534d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\n"
     ]
    }
   ],
   "source": [
    "cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4063218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "#cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\NSL-KDD\n",
    "missing_values = [\"n/a\", \"na\", \"Infinity\", \"NaN\",\"nan\",\"-\",\"excel\",\"?\",\"#DIV/0!\",\"aza\"]\n",
    "df = pd.read_csv(\"df_training.csv\", na_values = missing_values, engine='python', skipinitialspace=True)\n",
    "df=df.fillna(df.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8ad6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656666, 79)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa4db388",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df[df['class3'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290b4f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scr_IP</th>\n",
       "      <th>Servicewebsocket</th>\n",
       "      <th>Servicessh</th>\n",
       "      <th>Servicesmtp</th>\n",
       "      <th>Servicesimple_service_discovery</th>\n",
       "      <th>Serviceprivate</th>\n",
       "      <th>Serviceother</th>\n",
       "      <th>Servicenetbios-ns</th>\n",
       "      <th>Servicemysql</th>\n",
       "      <th>Servicemqtt</th>\n",
       "      <th>...</th>\n",
       "      <th>std_num_cswch/s</th>\n",
       "      <th>OSSEC_alert</th>\n",
       "      <th>OSSEC_alert_level</th>\n",
       "      <th>Login_attempt</th>\n",
       "      <th>Succesful_login</th>\n",
       "      <th>File_activity</th>\n",
       "      <th>Process_activity</th>\n",
       "      <th>read_write_physical.process</th>\n",
       "      <th>is_privileged</th>\n",
       "      <th>class3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319533</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319534</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319535</th>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319536</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319537</th>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656661</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656662</th>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656663</th>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656664</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656665</th>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337133 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Scr_IP  Servicewebsocket  Servicessh  Servicesmtp  \\\n",
       "319533  0.542857               0.0         0.0          0.0   \n",
       "319534  0.542857               0.0         0.0          0.0   \n",
       "319535  0.457143               0.0         0.0          0.0   \n",
       "319536  0.085714               1.0         0.0          0.0   \n",
       "319537  0.314286               0.0         0.0          0.0   \n",
       "...          ...               ...         ...          ...   \n",
       "656661  0.571429               0.0         0.0          0.0   \n",
       "656662  0.457143               0.0         0.0          0.0   \n",
       "656663  0.542857               0.0         0.0          0.0   \n",
       "656664  0.571429               0.0         0.0          0.0   \n",
       "656665  0.457143               0.0         0.0          0.0   \n",
       "\n",
       "        Servicesimple_service_discovery  Serviceprivate  Serviceother  \\\n",
       "319533                              0.0             0.0           0.0   \n",
       "319534                              0.0             0.0           0.0   \n",
       "319535                              0.0             0.0           0.0   \n",
       "319536                              0.0             0.0           0.0   \n",
       "319537                              0.0             0.0           0.0   \n",
       "...                                 ...             ...           ...   \n",
       "656661                              0.0             0.0           0.0   \n",
       "656662                              0.0             0.0           0.0   \n",
       "656663                              0.0             0.0           0.0   \n",
       "656664                              0.0             0.0           0.0   \n",
       "656665                              0.0             0.0           0.0   \n",
       "\n",
       "        Servicenetbios-ns  Servicemysql  Servicemqtt  ...  std_num_cswch/s  \\\n",
       "319533                0.0           0.0          0.0  ...         0.254258   \n",
       "319534                0.0           0.0          0.0  ...         0.263953   \n",
       "319535                0.0           0.0          0.0  ...         0.223940   \n",
       "319536                0.0           0.0          0.0  ...         0.300815   \n",
       "319537                0.0           0.0          0.0  ...         0.245578   \n",
       "...                   ...           ...          ...  ...              ...   \n",
       "656661                0.0           0.0          0.0  ...         0.238433   \n",
       "656662                0.0           0.0          0.0  ...         0.240807   \n",
       "656663                0.0           0.0          0.0  ...         0.254394   \n",
       "656664                0.0           0.0          0.0  ...         0.245080   \n",
       "656665                0.0           0.0          0.0  ...         0.233497   \n",
       "\n",
       "        OSSEC_alert  OSSEC_alert_level  Login_attempt  Succesful_login  \\\n",
       "319533          0.0                0.0            1.0              1.0   \n",
       "319534          0.0                0.0            0.0              0.0   \n",
       "319535          0.0                0.0            0.0              0.0   \n",
       "319536          0.0                0.0            0.0              0.0   \n",
       "319537          0.0                0.0            0.0              0.0   \n",
       "...             ...                ...            ...              ...   \n",
       "656661          0.0                0.0            0.0              0.0   \n",
       "656662          0.0                0.0            0.0              0.0   \n",
       "656663          0.0                0.0            0.0              0.0   \n",
       "656664          0.0                0.0            0.0              0.0   \n",
       "656665          0.0                0.0            0.0              0.0   \n",
       "\n",
       "        File_activity  Process_activity  read_write_physical.process  \\\n",
       "319533            1.0               1.0                          1.0   \n",
       "319534            0.0               0.0                          1.0   \n",
       "319535            0.0               0.0                          0.0   \n",
       "319536            0.0               0.0                          1.0   \n",
       "319537            0.0               0.0                          0.0   \n",
       "...               ...               ...                          ...   \n",
       "656661            0.0               0.0                          1.0   \n",
       "656662            0.0               0.0                          0.0   \n",
       "656663            0.0               0.0                          1.0   \n",
       "656664            0.0               0.0                          1.0   \n",
       "656665            0.0               0.0                          0.0   \n",
       "\n",
       "        is_privileged  class3  \n",
       "319533            1.0     0.0  \n",
       "319534            0.0     0.0  \n",
       "319535            0.0     0.0  \n",
       "319536            0.0     0.0  \n",
       "319537            0.0     0.0  \n",
       "...               ...     ...  \n",
       "656661            0.0     0.0  \n",
       "656662            0.0     0.0  \n",
       "656663            0.0     0.0  \n",
       "656664            0.0     0.0  \n",
       "656665            0.0     0.0  \n",
       "\n",
       "[337133 rows x 79 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1700d2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337133, 79)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c33dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "#df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Filter out normal data and drop the class column\n",
    "#normal_data = df[df['class3'] == 0].drop('class3', axis=1)\n",
    "\n",
    "# Normalize data\n",
    "\n",
    "\n",
    "X = normal_data.drop('class3', axis=1).values\n",
    "y = normal_data['class3'].values\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_tensor, torch.tensor(y, dtype=torch.float32)), batch_size=32, shuffle=True)\n",
    "\n",
    "# DataLoader\n",
    "#train_loader = DataLoader(TensorDataset(X), batch_size=32, shuffle=True)\n",
    "#test_loader = DataLoader(TensorDataset(X_test), batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9f8b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/3\n",
      "Epoch 1/10, Loss: 0.6076\n",
      "Epoch 2/10, Loss: 0.2682\n",
      "Epoch 3/10, Loss: 0.2346\n",
      "Epoch 4/10, Loss: 0.2185\n",
      "Epoch 5/10, Loss: 0.2089\n",
      "Epoch 6/10, Loss: 0.1960\n",
      "Epoch 7/10, Loss: 0.1905\n",
      "Epoch 8/10, Loss: 0.1812\n",
      "Epoch 9/10, Loss: 0.1738\n",
      "Epoch 10/10, Loss: 0.1664\n",
      "Starting fold 2/3\n",
      "Epoch 1/10, Loss: 0.5753\n",
      "Epoch 2/10, Loss: 0.1924\n",
      "Epoch 3/10, Loss: 0.1594\n",
      "Epoch 4/10, Loss: 0.1453\n",
      "Epoch 5/10, Loss: 0.1367\n",
      "Epoch 6/10, Loss: 0.1307\n",
      "Epoch 7/10, Loss: 0.1252\n",
      "Epoch 8/10, Loss: 0.1202\n",
      "Epoch 9/10, Loss: 0.1165\n",
      "Epoch 10/10, Loss: 0.1144\n",
      "Starting fold 3/3\n",
      "Epoch 1/10, Loss: 0.6972\n",
      "Epoch 2/10, Loss: 0.3384\n",
      "Epoch 3/10, Loss: 0.3014\n",
      "Epoch 4/10, Loss: 0.2841\n",
      "Epoch 5/10, Loss: 0.2733\n",
      "Epoch 6/10, Loss: 0.2622\n",
      "Epoch 7/10, Loss: 0.2548\n",
      "Epoch 8/10, Loss: 0.2494\n",
      "Epoch 9/10, Loss: 0.2453\n",
      "Epoch 10/10, Loss: 0.2423\n",
      "Average Anomaly Detection Threshold: 0.007467526290565729\n"
     ]
    }
   ],
   "source": [
    "# Define the Autoencoder model\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3),  # Latent representation\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid(),  # Assuming the input data is normalized between 0 and 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Loss Function for AE\n",
    "def loss_function(recon_x, x):\n",
    "    MSE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    return MSE\n",
    "\n",
    "# Training Loop\n",
    "def train(model, train_loader, num_epochs=50):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch = model(data)\n",
    "            loss = loss_function(recon_batch, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader.dataset):.4f}')\n",
    "\n",
    "# Function to calculate the threshold for anomaly detection\n",
    "def calculate_threshold(model, val_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        errors = []\n",
    "        for data, _ in val_loader:\n",
    "            recon = model(data)\n",
    "            error = torch.mean((data - recon) ** 2, dim=1)\n",
    "            errors.extend(error.tolist())\n",
    "    threshold = np.percentile(errors, 95)  # Use the 95th percentile error as the threshold\n",
    "    return threshold\n",
    "\n",
    "n_splits = 3\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "thresholds = []\n",
    "\n",
    "# Assuming X_tensor is your pre-processed dataset ready for training\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_tensor)):\n",
    "    print(f'Starting fold {fold+1}/{n_splits}')\n",
    "    train_data = X_tensor[train_idx]\n",
    "    val_data = X_tensor[val_idx]\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(train_data, torch.zeros(len(train_idx))), batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(TensorDataset(val_data, torch.zeros(len(val_idx))), batch_size=32)\n",
    "    \n",
    "    model = AE(input_dim=X_tensor.shape[1])\n",
    "    train(model, train_loader, num_epochs=10)  # Adjust num_epochs as necessary\n",
    "    \n",
    "    threshold = calculate_threshold(model, val_loader)\n",
    "    thresholds.append(threshold)\n",
    "    \n",
    "    # Save model and threshold for each fold\n",
    "    torch.save(model.state_dict(), f'model_fold_MAG50{fold}.pth')\n",
    "    np.savetxt(f'threshold_fold_MAG50{fold}.txt', [threshold], delimiter=',')\n",
    "\n",
    "average_threshold = np.mean(thresholds)\n",
    "print(f'Average Anomaly Detection Threshold: {average_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b5beb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "988a9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per Fold: [0.4868923902111968, 0.48670878749291724, 0.48755043614676996]\n",
      "Mean Precision: 0.4871, Standard Deviation: 0.0004\n",
      "\n",
      "Recall per Fold: [0.9999749636973612, 1.0, 0.9998372640328477]\n",
      "Mean Recall: 0.9999, Standard Deviation: 0.0001\n",
      "\n",
      "F1_score per Fold: [0.6549073781815051, 0.6547466344282113, 0.6554728052358384]\n",
      "Mean F1_score: 0.6550, Standard Deviation: 0.0003\n",
      "\n",
      "Accuracy per Fold: [0.4872021343989084, 0.486824472491594, 0.48855440767993763]\n",
      "Mean Accuracy: 0.4875, Standard Deviation: 0.0007\n",
      "\n",
      "Auc_roc per Fold: [0.9694507870794028, 0.9736357597972234, 0.971139629968081]\n",
      "Mean Auc_roc: 0.9714, Standard Deviation: 0.0017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'scaler' is the MinMaxScaler fitted on your original dataset\n",
    "\n",
    "# Load and preprocess the new dataset\n",
    "new_df = pd.read_csv('df_testing.csv')\n",
    "\n",
    "# It seems you're intending to use a binary classification ('normal' vs. not 'normal')\n",
    "# Assuming 'class3' is your label column\n",
    "X_new = new_df.drop('class3', axis=1).values\n",
    "y_new = new_df['class3'].values\n",
    "\n",
    "# Normalize the new dataset\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "# Convert to tensors\n",
    "X_new_tensor = torch.tensor(X_new_scaled, dtype=torch.float32)\n",
    "y_new_tensor = torch.tensor(y_new, dtype=torch.long)\n",
    "\n",
    "def evaluate_model(model, X_tensor, y_true, threshold):\n",
    "    model.eval()\n",
    "    data_loader = DataLoader(TensorDataset(X_tensor, y_true), batch_size=32)\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in data_loader:\n",
    "            reconstruction = model(data)  # Only expect the reconstruction from the model\n",
    "            recon_error = torch.mean((data - reconstruction) ** 2, dim=1)\n",
    "            predictions.extend(recon_error.numpy())\n",
    "    \n",
    "    # Convert reconstruction errors to binary predictions based on the threshold\n",
    "    binary_predictions = np.array(predictions) > threshold\n",
    "    \n",
    "    # Calculate metrics\n",
    "    p = precision_score(y_true.numpy(), binary_predictions)\n",
    "    r = recall_score(y_true.numpy(), binary_predictions)\n",
    "    f1 = f1_score(y_true.numpy(), binary_predictions)\n",
    "    cm = confusion_matrix(y_true.numpy(), binary_predictions)\n",
    "    acc = accuracy_score(y_true.numpy(), binary_predictions)\n",
    "    auc_roc = roc_auc_score(y_true.numpy(), predictions)\n",
    "\n",
    "    return {'precision': p, 'recall': r, 'f1_score': f1, 'confusion_matrix': cm, 'accuracy': acc, 'auc_roc': auc_roc}\n",
    "\n",
    "\n",
    "# Load models, calculate metrics for each, and aggregate results\n",
    "metrics = {'precision': [], 'recall': [], 'f1_score': [], 'accuracy': [], 'auc_roc': []}\n",
    "n_folds = 3\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    # Load the saved model and threshold\n",
    "    model = AE(input_dim=78)\n",
    "    model.load_state_dict(torch.load(f'model_fold_MAG{fold}.pth'))\n",
    "    threshold = np.loadtxt(f'threshold_fold_MAG{fold}.txt')\n",
    "    \n",
    "    fold_metrics = evaluate_model(model, X_new_tensor, y_new_tensor, threshold)\n",
    "    \n",
    "    for key in metrics:\n",
    "        metrics[key].append(fold_metrics[key])\n",
    "\n",
    "# Calculate mean and standard deviation of metrics\n",
    "for metric in metrics:\n",
    "    mean_value = np.mean(metrics[metric])\n",
    "    std_value = np.std(metrics[metric])\n",
    "    print(f\"{metric.capitalize()} per Fold: {metrics[metric]}\")\n",
    "    print(f\"Mean {metric.capitalize()}: {mean_value:.4f}, Standard Deviation: {std_value:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b267a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Precision per Fold: [0.9464180352050349, 0.9467047376289797, 0.9465453511515496]\\nMean Precision: 0.9466, Standard Deviation: 0.0001\\n\\nRecall per Fold: [0.9638100245355766, 0.967064743878624, 0.9584772920735066]\\nMean Recall: 0.9631, Standard Deviation: 0.0035\\n\\nF1_score per Fold: [0.9550348557394129, 0.9567764388244181, 0.9524739542839372]\\nMean F1_score: 0.9548, Standard Deviation: 0.0018\\n\\nAccuracy per Fold: [0.9558379221285512, 0.9574825788216949, 0.9534562155840358]\\nMean Accuracy: 0.9556, Standard Deviation: 0.0017\\n\\nAuc_roc per Fold: [0.9697580152087358, 0.9757341994219888, 0.9709392604582278]\\nMean Auc_roc: 0.9721, Standard Deviation: 0.0026'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSG10TEST\n",
    "'''Precision per Fold: [0.9464180352050349, 0.9467047376289797, 0.9465453511515496]\n",
    "Mean Precision: 0.9466, Standard Deviation: 0.0001\n",
    "\n",
    "Recall per Fold: [0.9638100245355766, 0.967064743878624, 0.9584772920735066]\n",
    "Mean Recall: 0.9631, Standard Deviation: 0.0035\n",
    "\n",
    "F1_score per Fold: [0.9550348557394129, 0.9567764388244181, 0.9524739542839372]\n",
    "Mean F1_score: 0.9548, Standard Deviation: 0.0018\n",
    "\n",
    "Accuracy per Fold: [0.9558379221285512, 0.9574825788216949, 0.9534562155840358]\n",
    "Mean Accuracy: 0.9556, Standard Deviation: 0.0017\n",
    "\n",
    "Auc_roc per Fold: [0.9697580152087358, 0.9757341994219888, 0.9709392604582278]\n",
    "Mean Auc_roc: 0.9721, Standard Deviation: 0.0026\n",
    "\n",
    "\n",
    "Precision per Fold: [0.9464180352050349, 0.9467047376289797, 0.9465453511515496, 0.9464180352050349, 0.9467047376289797, 0.9465453511515496]\n",
    "Mean Precision: 0.9466, Standard Deviation: 0.0001\n",
    "\n",
    "Recall per Fold: [0.9638100245355766, 0.967064743878624, 0.9584772920735066, 0.9638100245355766, 0.967064743878624, 0.9584772920735066]\n",
    "Mean Recall: 0.9631, Standard Deviation: 0.0035\n",
    "\n",
    "F1_score per Fold: [0.9550348557394129, 0.9567764388244181, 0.9524739542839372, 0.9550348557394129, 0.9567764388244181, 0.9524739542839372]\n",
    "Mean F1_score: 0.9548, Standard Deviation: 0.0018\n",
    "\n",
    "Accuracy per Fold: [0.9558379221285512, 0.9574825788216949, 0.9534562155840358, 0.9558379221285512, 0.9574825788216949, 0.9534562155840358]\n",
    "Mean Accuracy: 0.9556, Standard Deviation: 0.0017\n",
    "\n",
    "Auc_roc per Fold: [0.9697580152087358, 0.9757341994219888, 0.9709392604582278, 0.9697580152087358, 0.9757341994219888, 0.9709392604582278]\n",
    "Mean Auc_roc: 0.9721, Standard Deviation: 0.0026\n",
    "\n",
    "Overall Confusion Matrix:\n",
    "[[239820  13032]\n",
    " [  8839 230813]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "917afa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision per Fold: [0.9464180352050349, 0.9467047376289797, 0.9465453511515496, 0.9464180352050349, 0.9467047376289797, 0.9465453511515496]\n",
      "Mean Precision: 0.9466, Standard Deviation: 0.0001\n",
      "\n",
      "Recall per Fold: [0.9638100245355766, 0.967064743878624, 0.9584772920735066, 0.9638100245355766, 0.967064743878624, 0.9584772920735066]\n",
      "Mean Recall: 0.9631, Standard Deviation: 0.0035\n",
      "\n",
      "F1_score per Fold: [0.9550348557394129, 0.9567764388244181, 0.9524739542839372, 0.9550348557394129, 0.9567764388244181, 0.9524739542839372]\n",
      "Mean F1_score: 0.9548, Standard Deviation: 0.0018\n",
      "\n",
      "Accuracy per Fold: [0.9558379221285512, 0.9574825788216949, 0.9534562155840358, 0.9558379221285512, 0.9574825788216949, 0.9534562155840358]\n",
      "Mean Accuracy: 0.9556, Standard Deviation: 0.0017\n",
      "\n",
      "Auc_roc per Fold: [0.9697580152087358, 0.9757341994219888, 0.9709392604582278, 0.9697580152087358, 0.9757341994219888, 0.9709392604582278]\n",
      "Mean Auc_roc: 0.9721, Standard Deviation: 0.0026\n",
      "\n",
      "Overall Confusion Matrix:\n",
      "[[239820  13032]\n",
      " [  8839 230813]]\n"
     ]
    }
   ],
   "source": [
    "# Continue from the previous setup...\n",
    "\n",
    "# Initialize storage for the components of the confusion matrix\n",
    "cm_components = {'TP': 0, 'FP': 0, 'FN': 0, 'TN': 0}\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    # Load the saved model and threshold\n",
    "    model = AE(input_dim=78)\n",
    "    model.load_state_dict(torch.load(f'model_fold_MAG{fold}.pth'))\n",
    "    threshold = np.loadtxt(f'threshold_fold_MAG{fold}.txt')\n",
    "    \n",
    "    fold_metrics = evaluate_model(model, X_new_tensor, y_new_tensor, threshold)\n",
    "    \n",
    "    for key in metrics:\n",
    "        metrics[key].append(fold_metrics[key])\n",
    "    \n",
    "    # Update confusion matrix components\n",
    "    cm = fold_metrics['confusion_matrix']\n",
    "    cm_components['TP'] += cm[1, 1]\n",
    "    cm_components['FP'] += cm[0, 1]\n",
    "    cm_components['FN'] += cm[1, 0]\n",
    "    cm_components['TN'] += cm[0, 0]\n",
    "\n",
    "# Construct the overall confusion matrix\n",
    "overall_cm = np.array([[cm_components['TN'], cm_components['FP']],\n",
    "                       [cm_components['FN'], cm_components['TP']]])\n",
    "\n",
    "# Calculate mean and standard deviation of metrics and print them along with the overall confusion matrix\n",
    "for metric in metrics:\n",
    "    if metric != 'confusion_matrix':  # Handle confusion matrix separately\n",
    "        mean_value = np.mean(metrics[metric])\n",
    "        std_value = np.std(metrics[metric])\n",
    "        print(f\"{metric.capitalize()} per Fold: {metrics[metric]}\")\n",
    "        print(f\"Mean {metric.capitalize()}: {mean_value:.4f}, Standard Deviation: {std_value:.4f}\\n\")\n",
    "\n",
    "print(f\"Overall Confusion Matrix:\\n{overall_cm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e76c750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON\n"
     ]
    }
   ],
   "source": [
    "cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8073dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, threshold):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            # Corrected to expect only one output from the model, which is the reconstruction\n",
    "            reconstruction = model(data)\n",
    "            recon_error = torch.mean((data - reconstruction) ** 2, dim=1)\n",
    "            # Ensure threshold is a tensor or a scalar\n",
    "            pred = (recon_error > torch.tensor(threshold, dtype=torch.float32)).int()\n",
    "            predictions.extend(pred.numpy())\n",
    "            actuals.extend(labels.numpy())\n",
    "    return predictions, actuals\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "\n",
    "# Specify the files to process\n",
    "files_to_process = [\n",
    "    'FSGM-XAAE-IIoT.csv', 'BIM-XAAE-IIoT.csv', 'DF-XAAE-IIoT.csv',\n",
    "    'JSMA-XAAE-IIoT.csv', 'CW2-XAAE-IIoT.csv', 'CWinf-XAAE-IIoT.csv'\n",
    "]\n",
    "\n",
    "ref_file = 'df_testing.csv'\n",
    "ref_df = pd.read_csv(ref_file)\n",
    "\n",
    "# Placeholder for results\n",
    "results = []\n",
    "\n",
    "for fold in range(3):  # Assuming 3 folds\n",
    "    model = AE(input_dim=78)  # Adjust parameters as necessary\n",
    "    model_path = f'model_fold_MAG50{fold}.pth'\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    threshold = np.loadtxt(f'threshold_fold_MAG50{fold}.txt')\n",
    "    \n",
    "    for file_name in files_to_process:\n",
    "        df = pd.read_csv(file_name)\n",
    "        df.columns = ref_df.columns\n",
    "        concatenated_df = pd.concat([ref_df, df], ignore_index=True)\n",
    "        \n",
    "        X_scaled = scaler.fit_transform(concatenated_df.iloc[:, :-1])\n",
    "        y_true = concatenated_df.iloc[:, -1].values\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_true, dtype=torch.long)\n",
    "        \n",
    "        data_loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=False)\n",
    "        predictions, actuals = evaluate_model(model, data_loader, threshold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(actuals, predictions)\n",
    "        precision = precision_score(actuals, predictions)\n",
    "        recall = recall_score(actuals, predictions)\n",
    "        f1 = f1_score(actuals, predictions)\n",
    "        roc_auc = roc_auc_score(actuals, predictions)\n",
    "        cm = confusion_matrix(actuals, predictions).flatten().tolist()  # Flatten CM to save in CSV\n",
    "        \n",
    "        results.append([fold, file_name, accuracy, precision, recall, f1, roc_auc] + cm)\n",
    "\n",
    "# Convert results to a DataFrame and save to CSV\n",
    "columns = ['Fold', 'File', 'Accuracy', 'Precision', 'Recall', 'F1_Score', 'AUC_ROC', \n",
    "           'TN', 'FP', 'FN', 'TP']  # Adjust as needed\n",
    "results_df = pd.DataFrame(results, columns=columns)\n",
    "results_df.to_csv('evaluation_metrics_MAG50.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "778f4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "\n",
    "# Assuming your model class and evaluate_model function are defined correctly...\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "\n",
    "files_to_process = [\n",
    "    'FSGM-XAAE-IIoT.csv', 'BIM-XAAE-IIoT.csv', 'DF-XAAE-IIoT.csv',\n",
    "    'JSMA-XAAE-IIoT.csv', 'CW2-XAAE-IIoT.csv', 'CWinf-XAAE-IIoT.csv'\n",
    "]\n",
    "\n",
    "ref_file = 'df_testing.csv'\n",
    "ref_df = pd.read_csv(ref_file)\n",
    "\n",
    "# Structure to hold raw results\n",
    "raw_results = {file: [] for file in files_to_process}\n",
    "\n",
    "for fold in range(3):  # For each fold\n",
    "    model_path = f'model_fold_MAG50{fold}.pth'\n",
    "    threshold = np.loadtxt(f'threshold_fold_MAG50{fold}.txt')\n",
    "\n",
    "    # Load model\n",
    "    model = AE(input_dim=78)  # Initialize your model here\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    for file_name in files_to_process:\n",
    "        df = pd.read_csv(file_name)\n",
    "        df.columns = ref_df.columns\n",
    "        concatenated_df = pd.concat([ref_df, df], ignore_index=True)\n",
    "        \n",
    "        X_scaled = scaler.fit_transform(concatenated_df.iloc[:, :-1])\n",
    "        y_true = concatenated_df.iloc[:, -1].values\n",
    "        \n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_true, dtype=torch.long)\n",
    "        \n",
    "        data_loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=32, shuffle=False)\n",
    "        \n",
    "        predictions, actuals = evaluate_model(model, data_loader, threshold)\n",
    "        \n",
    "        # Compute metrics\n",
    "        roc_auc = roc_auc_score(actuals, predictions)\n",
    "        \n",
    "        raw_results[file_name].append(roc_auc)\n",
    "\n",
    "# Prepare final results with mean/std AUC-ROC\n",
    "final_results = []\n",
    "\n",
    "for file_name, auc_roc_scores in raw_results.items():\n",
    "    mean_auc_roc = np.mean(auc_roc_scores)\n",
    "    std_auc_roc = np.std(auc_roc_scores)\n",
    "    final_results.append([file_name, mean_auc_roc, std_auc_roc])\n",
    "\n",
    "# Convert final results to a DataFrame and save to CSV\n",
    "final_df = pd.DataFrame(final_results, columns=['File', 'AUC_ROC_Mean', 'AUC_ROC_STD'])\n",
    "final_df.sort_values('File', inplace=True)\n",
    "final_df.to_csv('final_evaluation_metricsMAG50.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38276a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
