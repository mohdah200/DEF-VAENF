{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3664fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juba\\.conda\\envs\\py3.6\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import libs\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70ecc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inti\n",
    "lb_make=LabelEncoder()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94544081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\NSL-KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "547b7d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INput\n",
    "file_name='df_testing.csv'\n",
    "missing_values = [\"n/a\", \"na\", \"Infinity\", \"NaN\",\"nan\",\"-\",\"excel\",\"?\",\"#DIV/0!\",\"aza\"]\n",
    "df = pd.read_csv(\"../df_training.csv\", na_values = missing_values, engine='python', skipinitialspace=True)\n",
    "df=df.fillna(df.median())\n",
    "df = df[df['class3'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807aebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CDAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CDAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(78, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 42),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(42, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 78),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def add_noise(data, noise_factor=0.05):\n",
    "    noise = torch.randn_like(data) * noise_factor\n",
    "    data_noisy = data + noise\n",
    "    return data_noisy\n",
    "\n",
    "\n",
    "def loss_function(W, x, recons_x, h, lambda_w=1e-4):\n",
    "    mse_loss = F.mse_loss(recons_x, x)\n",
    "    dh = h * (1 - h)  # Derivative of sigmoid\n",
    "    w_sum = torch.sum(W**2)  # Ensure W is your weight tensor and sum of squares of weights\n",
    "    # Correct calculation of contractive loss\n",
    "    # Multiply the sum of squared derivatives by the sum of squared weights (scalar multiplication)\n",
    "    contractive_loss = torch.sum(dh**2) * w_sum\n",
    "    return mse_loss + lambda_w * contractive_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50285ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(data, noise_factor=0.05):\n",
    "    noise = torch.randn_like(data) * noise_factor\n",
    "    data_noisy = data + noise\n",
    "    return data_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc8157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    data = add_noise(data)  # Add noise to data\n",
    "    data = Variable(data.view(-1, 78))\n",
    "    optimizer.zero_grad()\n",
    "    recons = model(data)\n",
    "    loss = loss_function(model.encoder[2].weight, data, recons, model.encoder[1](model.encoder[0](data)))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# Load your data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "292cc822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data here\n",
    "normal_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f095c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337133, 79)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2cc44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 433.2774\n",
      "Epoch [2/10], Loss: 388.7471\n",
      "Epoch [3/10], Loss: 347.3539\n",
      "Epoch [4/10], Loss: 309.0034\n",
      "Epoch [5/10], Loss: 273.5293\n",
      "Epoch [6/10], Loss: 240.9986\n",
      "Epoch [7/10], Loss: 211.2164\n",
      "Epoch [8/10], Loss: 184.2187\n",
      "Epoch [9/10], Loss: 159.7669\n",
      "Epoch [10/10], Loss: 137.9759\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()  # default=(0, 1)\n",
    "features = normal_data.iloc[:, :-1]\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Convert back to dataframe\n",
    "features = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "\n",
    "# Convert the dataframe to a tensor\n",
    "features = torch.tensor(features.values, dtype=torch.float32)\n",
    "\n",
    "# Create the model\n",
    "model = CDAE()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train the model on normal data\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, features, optimizer)\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837b3495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([337133, 78])\n"
     ]
    }
   ],
   "source": [
    "print(features.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3e179d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the second CSV file and transform the data into tensors\\ndf_adv = pd.read_csv(file_name)\\n\\nadv_features = df_adv.iloc[:, :-1].values\\nadv_labels = df_adv.iloc[:, -1].values\\n\\n\\n# Convert to tensor\\nadv_features = torch.from_numpy(adv_features).float()\\nadv_labels = torch.from_numpy(adv_labels).long()\\n\\n# Evaluate model on adversarial data\\nmodel.eval()\\nwith torch.no_grad():\\n    reconstructed = model(adv_features)\\ndf_out = pd.DataFrame(reconstructed.numpy())\\ndf_out['42 Labels'] = adv_labels.numpy()\\ndf_out.to_csv('test-CDAE-KDD.csv', index=False)\\n# Save output to csv\\ndf_out = pd.DataFrame(reconstructed.numpy())\\ndf_out['42 Labels'] = adv_labels.numpy()\\ndf_out.to_csv('test-CDAE-KDD.csv', index=False)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load the second CSV file and transform the data into tensors\n",
    "df_adv = pd.read_csv(file_name)\n",
    "\n",
    "adv_features = df_adv.iloc[:, :-1].values\n",
    "adv_labels = df_adv.iloc[:, -1].values\n",
    "\n",
    "\n",
    "# Convert to tensor\n",
    "adv_features = torch.from_numpy(adv_features).float()\n",
    "adv_labels = torch.from_numpy(adv_labels).long()\n",
    "\n",
    "# Evaluate model on adversarial data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(adv_features)\n",
    "df_out = pd.DataFrame(reconstructed.numpy())\n",
    "df_out['42 Labels'] = adv_labels.numpy()\n",
    "df_out.to_csv('test-CDAE-KDD.csv', index=False)\n",
    "# Save output to csv\n",
    "df_out = pd.DataFrame(reconstructed.numpy())\n",
    "df_out['42 Labels'] = adv_labels.numpy()\n",
    "df_out.to_csv('test-CDAE-KDD.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510f0e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON\n"
     ]
    }
   ],
   "source": [
    " cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52931fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(file_name, model, scaler, output_file):\n",
    "    # Load the CSV file\n",
    "    df_adv = pd.read_csv(file_name)\n",
    "    \n",
    "    # Assuming the last column is the label\n",
    "    adv_features = df_adv.iloc[:, :-1]\n",
    "    adv_labels = df_adv.iloc[:, -1].values\n",
    "    \n",
    "    # Apply the same scaling as the original data\n",
    "    adv_features_scaled = scaler.transform(adv_features)  # Use the same scaler as for training data\n",
    "    \n",
    "    # Convert to tensor\n",
    "    adv_features_tensor = torch.tensor(adv_features_scaled, dtype=torch.float32)\n",
    "    \n",
    "    # Evaluate model on this data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(adv_features_tensor)\n",
    "        \n",
    "    # Convert reconstructed data back to numpy array (if needed)\n",
    "    reconstructed_np = reconstructed.numpy()\n",
    "    \n",
    "    # Create a DataFrame from the reconstructed features\n",
    "    df_out = pd.DataFrame(reconstructed_np, columns=adv_features.columns)\n",
    "    \n",
    "    # Append the labels column\n",
    "    df_out['class3'] = adv_labels\n",
    "    \n",
    "    # Save to CSV\n",
    "    df_out.to_csv(output_file, index=False)\n",
    "\n",
    "# Example usage:\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "scaler = MinMaxScaler().fit(features)  # Assuming 'features' is your training features DataFrame\n",
    "\n",
    "# Assuming you have a list of file names to process\n",
    "file_names = ['FSGM-XAAE-IIoT.csv', 'BIM-XAAE-IIoT.csv', 'DF-XAAE-IIoT.csv', 'JSMA-XAAE-IIoT.csv', 'CW2-XAAE-IIoT.csv', 'CWinf-XAAE-IIoT.csv']\n",
    "output_files = ['FSGM-CDAE-IIoT.csv', 'BIM-CDAE-IIoT.csv', 'DF-CDAE-IIoT.csv', 'JSMA-CDAE-IIoT.csv', 'CW2-CDAE-IIoT.csv','CWinf-CDAE-IIoT.csv']\n",
    "\n",
    "for file_name, output_file in zip(file_names, output_files):\n",
    "    preprocess_and_save(file_name, model, scaler, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "337789e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172666d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Apply the trained DAE to denoise the adversarial samples\n",
    "adversarial_data = pd.read_csv('df_training.csv')\n",
    "adversarial_features = adversarial_data.drop('class3', axis=1).values\n",
    "X_adv = torch.from_numpy(adversarial_features).float()\n",
    "denoised_output = model(X_adv)\n",
    "\n",
    "# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\n",
    "denoised_samples = denoised_output.detach().numpy()\n",
    "#denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "\n",
    "# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\n",
    "denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\n",
    "denoised_data['class3'] = adversarial_data['class3']\n",
    "\n",
    "denoised_data.to_csv('df_training_CDAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5beadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Apply the trained DAE to denoise the adversarial samples\n",
    "adversarial_data = pd.read_csv('df_testing.csv')\n",
    "adversarial_features = adversarial_data.drop('class3', axis=1).values\n",
    "X_adv = torch.from_numpy(adversarial_features).float()\n",
    "denoised_output = model(X_adv)\n",
    "\n",
    "# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\n",
    "denoised_samples = denoised_output.detach().numpy()\n",
    "#denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "\n",
    "# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\n",
    "denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\n",
    "denoised_data['class3'] = adversarial_data['class3']\n",
    "\n",
    "denoised_data.to_csv('df_testing_CDAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c21529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE\n"
     ]
    }
   ],
   "source": [
    " cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c509f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'CDAE_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d6993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
