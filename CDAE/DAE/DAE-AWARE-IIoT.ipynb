{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf67847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "lb_make=LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d74bb9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inti\n",
    "lb_make=LabelEncoder()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13767b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\adversarial_analysis-master\\\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\\\XAAE-IIoT\\\\CDAE_DAE'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c727651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INput\n",
    "file_name='../df_testing.csv'\n",
    "missing_values = [\"n/a\", \"na\", \"Infinity\", \"NaN\",\"nan\",\"-\",\"excel\",\"?\",\"#DIV/0!\",\"aza\"]\n",
    "df = pd.read_csv(\"../df_training.csv\", na_values = missing_values, engine='python', skipinitialspace=True)\n",
    "df=df.fillna(df.median())\n",
    "df = df[df['class3'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d9da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = df\n",
    "features = normal_data.drop('class3', axis=1).values\n",
    "\n",
    "# Apply MinMaxScaler to normalize the features between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "X_train = torch.from_numpy(scaled_features).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba4b0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the architecture of the denoising autoencoder\n",
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(78, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 18),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(18, 36),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(36, 78),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "223b244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create an instance of the Denoising Autoencoder\n",
    "dae = DenoisingAutoencoder()\n",
    "\n",
    "# Step 5: Set the number of training epochs, learning rate, and other hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "corruption_ratio = 0.2\n",
    "\n",
    "# Step 6: Define the reconstruction loss function (mean squared error) and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(dae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd8a7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Training loop\n",
    "# Step 4: Create an instance of the Denoising Autoencoder\n",
    "dae = DenoisingAutoencoder()\n",
    "\n",
    "# Step 5: Set the number of training epochs, learning rate, and other hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "corruption_ratio = 0.2\n",
    "\n",
    "# Step 6: Define the reconstruction loss function (mean squared error) and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(dae.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle and batch the training samples\n",
    "    indices = torch.randperm(X_train.size(0))\n",
    "    shuffled_X_train = X_train[indices]\n",
    "    batches = shuffled_X_train.split(batch_size, dim=0)\n",
    "\n",
    "    for batch in batches:\n",
    "        # Corrupt the input batch by adding noise\n",
    "        corrupted_batch = batch + torch.randn_like(batch) * corruption_ratio\n",
    "\n",
    "        # Forward pass\n",
    "        output = dae(corrupted_batch)\n",
    "\n",
    "        # Compute the reconstruction loss\n",
    "        loss = criterion(output, batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4a0466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Apply the trained DAE to denoise the adversarial samples\n",
    "adversarial_data = pd.read_csv(file_name)\n",
    "adversarial_features = adversarial_data.drop('class3', axis=1).values\n",
    "X_adv = torch.from_numpy(adversarial_features).float()\n",
    "denoised_output = dae(X_adv)\n",
    "\n",
    "# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\n",
    "denoised_samples = denoised_output.detach().numpy()\n",
    "#denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "\n",
    "# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\n",
    "denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\n",
    "denoised_data['class3'] = adversarial_data['class3']\n",
    "\n",
    "denoised_data.to_csv('df_testing_DAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dec39c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Apply the trained DAE to denoise the adversarial samples\n",
    "adversarial_data = pd.read_csv('../../df_training.csv')\n",
    "adversarial_features = adversarial_data.drop('class3', axis=1).values\n",
    "X_adv = torch.from_numpy(adversarial_features).float()\n",
    "denoised_output = dae(X_adv)\n",
    "\n",
    "# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\n",
    "denoised_samples = denoised_output.detach().numpy()\n",
    "#denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "\n",
    "# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\n",
    "denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\n",
    "denoised_data['class3'] = adversarial_data['class3']\n",
    "\n",
    "denoised_data.to_csv('df_training_DAE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d205d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE\\Cleaned_DAE_IIoT\n"
     ]
    }
   ],
   "source": [
    "cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE\\Cleaned_DAE_IIoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "547e456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenoisingAutoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=78, out_features=36, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=36, out_features=18, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=18, out_features=3, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=18, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=18, out_features=36, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=36, out_features=78, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dae = DenoisingAutoencoder()\n",
    "dae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "baf995b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON\n"
     ]
    }
   ],
   "source": [
    "cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78759174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files\n",
    "csv_files = ['FSGM-XAAE-IIoT.csv', 'BIM-XAAE-IIoT.csv', 'DF-XAAE-IIoT.csv', 'JSMA-XAAE-IIoT.csv', 'CW2-XAAE-IIoT.csv', 'CWinf-XAAE-IIoT.csv']\n",
    "file_name\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for file_name in csv_files:\n",
    "    # Load the adversarial sample data\n",
    "    adversarial_data = pd.read_csv(file_name)\n",
    "    \n",
    "    # Separate features and labels\n",
    "    adversarial_features = adversarial_data.iloc[:, :-1]\n",
    "    labels = adversarial_data.iloc[:, -1]\n",
    "\n",
    "    \n",
    "    # Scale features\n",
    "    features_scaled = scaler.fit_transform(adversarial_features)\n",
    "    \n",
    "    # Convert scaled features to tensor\n",
    "    X_adv = torch.from_numpy(features_scaled).float()\n",
    "    \n",
    "    # Apply the DAE model to denoise\n",
    "    with torch.no_grad():\n",
    "        denoised_output = dae(X_adv)\n",
    "    \n",
    "    # Convert the denoised output tensor back to a NumPy array\n",
    "    denoised_samples = denoised_output.detach().numpy()\n",
    "    \n",
    "    # Optionally, if you want to inverse transform the denoised data to its original scale:\n",
    "    # denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "    \n",
    "    # Create a DataFrame with the denoised samples\n",
    "    denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_features.columns)\n",
    "    denoised_data.iloc[:, -1] = labels\n",
    "    \n",
    "    # Construct output file name and save the denoised DataFrame to CSV\n",
    "    output_file_name = 'DAE_' + file_name\n",
    "    denoised_data.to_csv(output_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cb90f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load the adversarial sample data\\nadversarial_data = pd.read_csv('train-KDD.csv')\\n\\n# Separate features and labels\\nadversarial_features = adversarial_data.drop('42 Labels', axis=1).values\\n\\n# Initialize the MinMaxScaler\\nscaler = MinMaxScaler()\\n\\n# Fit and transform the adversarial features\\nfeatures_scaled = scaler.fit_transform(adversarial_features)\\n\\n# Convert scaled features to PyTorch tensor\\nX_adv = torch.from_numpy(features_scaled).float()\\ndenoised_output = dae(X_adv)\\n\\n# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\\ndenoised_samples = denoised_output.detach().numpy()\\n#denoised_samples = scaler.inverse_transform(denoised_samples)\\n\\n# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\\ndenoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\\ndenoised_data['42 Labels'] = adversarial_data['42 Labels']\\n\\ndenoised_data.to_csv('train-DAE-KDD.csv', index=False)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load the adversarial sample data\n",
    "adversarial_data = pd.read_csv('train-KDD.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "adversarial_features = adversarial_data.drop('42 Labels', axis=1).values\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the adversarial features\n",
    "features_scaled = scaler.fit_transform(adversarial_features)\n",
    "\n",
    "# Convert scaled features to PyTorch tensor\n",
    "X_adv = torch.from_numpy(features_scaled).float()\n",
    "denoised_output = dae(X_adv)\n",
    "\n",
    "# Step 9: Convert the denoised output tensor back to a NumPy array and rescale\n",
    "denoised_samples = denoised_output.detach().numpy()\n",
    "#denoised_samples = scaler.inverse_transform(denoised_samples)\n",
    "\n",
    "# Step 10: Create a DataFrame with the denoised samples and assign the label 'class3'\n",
    "denoised_data = pd.DataFrame(denoised_samples, columns=adversarial_data.columns[:-1])\n",
    "denoised_data['42 Labels'] = adversarial_data['42 Labels']\n",
    "\n",
    "denoised_data.to_csv('train-DAE-KDD.csv', index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19a09d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE\n"
     ]
    }
   ],
   "source": [
    " cd C:\\adversarial_analysis-master\\Investigating_the_Practicality_of_Adversarial_Evasion_Attacks_on_Network_Intrusion_Detection\\XAAE-IIoT\\CDAE_DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "682c7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dae.state_dict(), 'DAE_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360bc7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
